{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed4cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import deepbayesHF\n",
    "import deepbayesHF.optimizers as optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b738a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "X_train = X_train.astype(\"float32\").reshape(-1, 28*28)\n",
    "X_test = X_test.astype(\"float32\").reshape(-1, 28* 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071541b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation=\"relu\", input_shape=(None, 28*28)))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fa8f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This optimizer does not have a default compilation method. Please make sure to call the correct .compile method before use.\n",
      "deepbayes: Using implicit prior\n",
      "(784, 16) 0.03571428571428571\n",
      "(16, 10) 0.25\n",
      "deepbayes: Using implicit prior\n",
      "(784, 16) 0.03571428571428571\n",
      "(16, 10) 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                          | 0/469 [00:00<?, ?it/s]/home/matker/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:08<00:00, 54.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.951, acc: 0.067, val_loss: 0.662, val_acc: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 59.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: 0.684, acc: 0.067, val_loss: 0.636, val_acc: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 60.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss: 0.556, acc: 0.067, val_loss: 0.548, val_acc: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 59.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss: 0.498, acc: 0.067, val_loss: 0.416, val_acc: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:08<00:00, 58.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 0.407, acc: 0.070, val_loss: 0.362, val_acc: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 58.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss: 0.354, acc: 0.065, val_loss: 0.323, val_acc: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 61.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss: 0.315, acc: 0.063, val_loss: 0.297, val_acc: 0.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 60.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss: 0.284, acc: 0.069, val_loss: 0.266, val_acc: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 59.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss: 0.260, acc: 0.061, val_loss: 0.255, val_acc: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 59.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 0.239, acc: 0.068, val_loss: 0.238, val_acc: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:07<00:00, 60.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss: 0.228, acc: 0.062, val_loss: 0.224, val_acc: 0.072\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.35; decay=0.0\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "bayes_model = opt.compile(model, loss_fn=loss, epochs=10, learning_rate=learning_rate, batch_size=128)\n",
    "bayes_model.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65505fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('classes', 10)\n",
      "('batch_size', 128)\n",
      "('learning_rate', 0.35)\n",
      "('decay', 0.0)\n",
      "('epochs', 11)\n",
      "('inflate_prior', 1)\n",
      "('input_noise', 0.0)\n",
      "('robust_train', 0)\n",
      "('epsilon', 0.10000000000000002)\n",
      "('robust_lambda', 0.5)\n",
      "('loss_monte_carlo', 2)\n",
      "('input_upper', inf)\n",
      "('input_lower', -inf)\n",
      "('beta_1', 0.999)\n",
      "('beta_2', 0.9999)\n",
      "('lam', 1.0)\n",
      "('N', 60000)\n",
      "('max_eps', 0.1)\n",
      "('max_robust_lambda', 0.5)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "bayes_model.save(\"PosteriorModels/VOGN_MNIST_Posterior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08deab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, None, 16)          12560     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 10)          170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,730\n",
      "Trainable params: 12,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "BayesKeras detected the above model \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "from deepbayesHF import PosteriorModel\n",
    "\n",
    "bayes_model = PosteriorModel(\"PosteriorModels/VOGN_MNIST_Posterior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d757c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bayes_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ca2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 734451.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "y_cls = np.argmax(y_pred, axis=1)\n",
    "corr = 0\n",
    "for i in trange(len(y_cls)):\n",
    "    corr += int(y_cls[i] == y_test[i])\n",
    "print(\"Test set accuracy: \", corr/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16b58642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! THIS IS ONLY FOR RELU !! NO OTHER ACTIVATION SUPPORTED\n",
    "def get_alphas_betas(zeta_l, zeta_u, activation=\"relu\"):\n",
    "    zeta_l, zeta_u = np.squeeze(zeta_l), np.squeeze(zeta_u)\n",
    "    alpha_L, alpha_U = list([]), list([])\n",
    "    beta_L, beta_U = list([]), list([])\n",
    "    print(zeta_l.shape)\n",
    "    for i in range(len(zeta_l)):\n",
    "        if(zeta_u[i] <= 0):\n",
    "            alpha_U.append(0); alpha_L.append(0); beta_L.append(0); beta_U.append(0)\n",
    "        elif(zeta_l[i] >= 0):\n",
    "            alpha_U.append(1); alpha_L.append(1); beta_L.append(0); beta_U.append(0)\n",
    "        else:\n",
    "            # For relu I have the points (zeta_l, 0) and (zeta_u, zeta_u)\n",
    "            a_U = zeta_u[i]/(zeta_u[i]-zeta_l[i]); b_U = -1*(a_U*zeta_l[i])\n",
    "    \n",
    "            #a_L = a_U ; b_L = 0\n",
    "            #if (zeta_u[i] + zeta_l[i]) >= 0:\n",
    "            #    a_L = 1 ;   b_L = 0\n",
    "            #else:\n",
    "            a_L = 0 ;   b_L = 0    \n",
    "            alpha_U.append(a_U); alpha_L.append(a_L); beta_L.append(b_L); beta_U.append(b_U)\n",
    "    return [alpha_U], [beta_U], [alpha_L], [beta_L]\n",
    "\n",
    "\n",
    "\n",
    "def get_bar_lower(linear_bound_coef, mu_l, mu_u,\n",
    "                  nu_l, nu_u, lam_l, lam_u):\n",
    "    lam_l, lam_u = np.squeeze(lam_l), np.squeeze(lam_u)\n",
    "    mu_l = np.squeeze(mu_l); mu_u = np.squeeze(mu_u); \n",
    "    #nu_l = np.squeeze(nu_l); nu_u = np.squeeze(nu_u); \n",
    "    #lam_l = np.squeeze(lam_l); lam_u = np.squeeze(lam_u); \n",
    "    #linear_bound_coef= np.squeeze(linear_bound_coef)\n",
    "    mu_bar, nu_bar, lam_bar = [], [], []\n",
    "    #coef of the form - alpha_U, beta_U, alpha_L, beta_L\n",
    "    for i in range(len(linear_bound_coef)):\n",
    "        if(linear_bound_coef[i,2] >= 0):\n",
    "            mu_bar.append(linear_bound_coef[i,2] * mu_l[i])\n",
    "            nu_bar.append(linear_bound_coef[i,2] * nu_l[i])\n",
    "            lam_bar.append(linear_bound_coef[i,2] * lam_l[i] + linear_bound_coef[i,3])\n",
    "        else:\n",
    "            mu_bar.append(linear_bound_coef[i,2] * mu_u[i])\n",
    "            nu_bar.append(linear_bound_coef[i,2] * nu_u[i])\n",
    "            lam_bar.append(linear_bound_coef[i,2] * lam_u[i] + linear_bound_coef[i,3])\n",
    "    return np.asarray(mu_bar), np.asarray(nu_bar), np.asarray(lam_bar)\n",
    "\n",
    "def get_bar_upper(linear_bound_coef, mu_l, mu_u,\n",
    "                  nu_l, nu_u, lam_l, lam_u):\n",
    "    lam_l, lam_u = np.squeeze(lam_l), np.squeeze(lam_u)\n",
    "    mu_l = np.squeeze(mu_l); mu_u = np.squeeze(mu_u);  \n",
    "    #lam_l = np.squeeze(lam_l); lam_u = np.squeeze(lam_u); \n",
    "    mu_bar, nu_bar, lam_bar = [], [], []\n",
    "    #coef of the form - alpha_U, beta_U, alpha_L, beta_L\n",
    "    for i in range(len(linear_bound_coef)):\n",
    "        if(linear_bound_coef[i,0] >= 0):\n",
    "            mu_bar.append(linear_bound_coef[i,0] * mu_u[i])\n",
    "            nu_bar.append(linear_bound_coef[i,0] * nu_u[i])\n",
    "            lam_bar.append(linear_bound_coef[i,0] * lam_u[i] + linear_bound_coef[i,1])\n",
    "        else:\n",
    "            mu_bar.append(linear_bound_coef[i,0] * mu_l[i])\n",
    "            nu_bar.append(linear_bound_coef[i,0] * nu_l[i])\n",
    "            lam_bar.append(linear_bound_coef[i,0] * lam_l[i] + linear_bound_coef[i,1])\n",
    "    return np.asarray(mu_bar), np.asarray(nu_bar), np.asarray(lam_bar)\n",
    "\n",
    "def get_abc_lower(w, mu_l_bar, nu_l_bar, la_l_bar,\n",
    "               mu_u_bar, nu_u_bar, la_u_bar):\n",
    "    print(\"W shape: \", w.shape)\n",
    "    print(\"Nu shape: \", nu_l_bar.shape, nu_u_bar.shape)\n",
    "    a, b, c = [], [], []\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w[i])):\n",
    "            if(w[i][j] >= 0):\n",
    "                a.append(w[i][j] * mu_l_bar[i])\n",
    "                b.append(w[i][j] * nu_l_bar[i])\n",
    "                c.append(w[i][j] * la_l_bar[i])\n",
    "            else:\n",
    "                a.append(w[i][j] * mu_u_bar[i])\n",
    "                b.append(w[i][j] * nu_u_bar[i])\n",
    "                c.append(w[i][j] * la_u_bar[i])\n",
    "    return np.asarray(a), np.asarray(b), np.asarray(c)\n",
    "\n",
    "\n",
    "def get_abc_upper(w, mu_l_bar, nu_l_bar, la_l_bar,\n",
    "               mu_u_bar, nu_u_bar, la_u_bar):\n",
    "    #This is anarchy\n",
    "    return get_abc_lower(w,mu_u_bar, nu_u_bar, la_u_bar,\n",
    "                         mu_l_bar, nu_l_bar, la_l_bar)\n",
    "\n",
    "\n",
    "def min_of_linear_fun(coef_vec, uppers, lowers):\n",
    "    print(coef_vec.shape, uppers.shape, lowers.shape)\n",
    "    #getting the minimum\n",
    "    val_min = 0\n",
    "    for i in range(len(coef_vec)):\n",
    "        if coef_vec[i] >=0:\n",
    "            val_min = val_min + coef_vec[i]*lowers[i]\n",
    "        else: \n",
    "            val_min = val_min + coef_vec[i]*uppers[i]\n",
    "    return val_min\n",
    "\n",
    "def max_of_linear_fun(coef_vec, uppers, lowers):\n",
    "    val_max = - min_of_linear_fun(-coef_vec, uppers, lowers)\n",
    "    return val_max\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Linear Propogation Function\n",
    "\"\"\"\n",
    "\n",
    "def my_relu(arr):\n",
    "    arr = arr * (arr > 0)\n",
    "    return arr\n",
    "\n",
    "import pickle\n",
    "def propogate_lines(model, x, in_reg, w_margin=0.25, act = 'relu'):\n",
    "    x = np.asarray(x); x = x.astype('float64')\n",
    "    x_l, x_u = in_reg[0], in_reg[1]\n",
    "    [mW_0, mb_0, mW_1, mb_1] = model.posterior_mean\n",
    "    [dW_0, db_0, dW_1, db_1] = model.posterior_var\n",
    "    [sW_0, sb_0, sW_1, sb_1] = model.sample()\n",
    "    \n",
    "    [mW_0, mb_0, mW_1, mb_1] = [mW_0.numpy(), mb_0.numpy(), mW_1.numpy(), mb_1.numpy()]\n",
    "    [dW_0, db_0, dW_1, db_1] = [dW_0.numpy(), db_0.numpy(), dW_1.numpy(), db_1.numpy()]\n",
    "    #[sW_0, sb_0, sW_1, sb_1] = [sW_0.numpy(), sb_0.numpy(), sW_1.numpy(), sb_1.numpy()]\n",
    "    \n",
    "    #Actual code from now on    \n",
    "    W_0_L, W_0_U, b_0_L, b_0_U = sW_0 - dW_0*w_margin,  sW_0 + dW_0*w_margin, sb_0-db_0*w_margin, sb_0+db_0*w_margin\n",
    "    \n",
    "    W_0_L = W_0_L.T\n",
    "    W_0_U = W_0_U.T\n",
    "    \n",
    "    mu_0_L = W_0_L; mu_0_U = W_0_U\n",
    "    \n",
    "    print(sW_0[0])\n",
    "    n_hidden_1 = len(sW_0[0]) \n",
    "    \n",
    "    nu_0_L = np.asarray([x_l for i in range(n_hidden_1) ])\n",
    "    nu_0_U = np.asarray([x_l for i in range(n_hidden_1) ])\n",
    "\n",
    "    la_0_L = - np.dot(x_l, W_0_L.T) + b_0_L\n",
    "    la_0_U = - np.dot(x_l, W_0_U.T) + b_0_U\n",
    "    \n",
    "    # getting bounds on pre-activation fucntion\n",
    "    zeta_0_L = [ (min_of_linear_fun(np.concatenate((mu_0_L[i].flatten(), nu_0_L[i].flatten())), \n",
    "                                     np.concatenate((np.asarray(x_u).flatten(), W_0_U[i].flatten() )),\n",
    "                                     np.concatenate((np.asarray(x_l).flatten(), W_0_U[i].flatten() ))  )) for i in range(n_hidden_1)] \n",
    "    zeta_0_L = np.asarray(zeta_0_L) + la_0_L\n",
    "     \n",
    "    zeta_0_U = [ (max_of_linear_fun(np.concatenate((mu_0_U[i].flatten(), nu_0_U[i].flatten())),\n",
    "                                     np.concatenate((np.asarray(x_u).flatten(), W_0_U[i].flatten())),\n",
    "                                     np.concatenate((np.asarray(x_l).flatten(), W_0_L[i].flatten()))  )) for i in range(n_hidden_1)]\n",
    "        \n",
    "    zeta_0_U = np.asarray(zeta_0_U) + la_0_U\n",
    "    print(\"Zeta Shapes: \", zeta_0_L.shape, zeta_0_U.shape)\n",
    "    \n",
    "    # These are our linear upper and lower bounds for the activation function\n",
    "    LUB = np.asarray(get_alphas_betas(zeta_0_L, zeta_0_U))\n",
    "    #LUB = np.reshape(LUB, (-1, 4))\n",
    "    LUB = np.asmatrix(LUB).transpose() \n",
    "    # Now evaluate eq (*) conditions:\n",
    "    mu_0_L_bar, nu_0_L_bar, la_0_L_bar = get_bar_lower(LUB, mu_0_L, mu_0_U, \n",
    "                                                       nu_0_L, nu_0_U, \n",
    "                                                      la_0_L, la_0_U)\n",
    "    nu_0_L_bar = np.squeeze(nu_0_L_bar)\n",
    "    print(\"Bar shapes: \", mu_0_L_bar.shape, nu_0_L_bar.shape, la_0_L_bar.shape)\n",
    "    mu_0_U_bar, nu_0_U_bar, la_0_U_bar = get_bar_upper(LUB, mu_0_L, mu_0_U, \n",
    "                                                       nu_0_L, nu_0_U,\n",
    "                                                      la_0_L, la_0_U)\n",
    "    nu_0_U_bar = np.squeeze(nu_0_U_bar)\n",
    "    print(\"Bar shapes: \", mu_0_L_bar.shape, nu_0_L_bar.shape, la_0_L_bar.shape)\n",
    "    print(\"Bar shapes: \", mu_0_U_bar.shape, nu_0_U_bar.shape, la_0_U_bar.shape)\n",
    "    \n",
    "    z_1_L = my_relu(zeta_0_L)\n",
    "    z_1_U = my_relu(zeta_0_U)\n",
    "    \n",
    "    #Second layer\n",
    "    W_1_L, W_1_U, b_1_L, b_1_U = sW_1 - dW_1*w_margin,  sW_1 + dW_1*w_margin, sb_1 - db_1*w_margin, sb_1 + db_1*w_margin\n",
    "    \n",
    "    print(\"In Shapes: \", W_1_L.shape, mu_0_L_bar.shape, nu_0_L_bar.shape, la_0_L_bar.shape,\n",
    "                                   mu_0_U_bar.shape, nu_0_U_bar.shape, la_0_U_bar.shape)\n",
    "    \n",
    "    a_L, b_L, c_L = get_abc_lower(W_1_L, mu_0_L_bar, nu_0_L_bar, la_0_L_bar,\n",
    "                                   mu_0_U_bar, nu_0_U_bar, la_0_U_bar)\n",
    "\n",
    "    a_U, b_U, c_U = get_abc_upper(W_1_U, mu_0_L_bar, nu_0_L_bar, la_0_L_bar,\n",
    "                           mu_0_U_bar, nu_0_U_bar, la_0_U_bar)\n",
    "    \n",
    "    print(\"ABC shapes: \", a_L.shape, b_L.shape, c_L.shape)\n",
    "    print(\"ABC shapes: \", a_U.shape, b_U.shape, c_U.shape)\n",
    "    \n",
    "    mu_1_l = np.sum(a_L, axis=0); mu_1_u = np.sum(a_U, axis=0)\n",
    "    nu_12_l = z_1_L; \n",
    "    nu_12_u = z_1_L\n",
    "    nu_02_l = b_L; \n",
    "    nu_02_u = b_U\n",
    "    #la_1_l = np.sum(c_L, axis=0) - np.dot(z_1_L, W_1_L) + b_1_L\n",
    "    #la_1_u = np.sum(c_U, axis=0) - np.dot(z_1_L, W_1_U) + b_1_U\n",
    "    la_1_l = np.sum(c_L) - np.dot(z_1_L, W_1_L) + b_1_L\n",
    "    la_1_u = np.sum(c_U) - np.dot(z_1_L, W_1_U) + b_1_U\n",
    "    la_1_l = np.squeeze(la_1_l)\n",
    "    la_1_u = np.squeeze(la_1_u)\n",
    "    \n",
    "    mu_1_l = np.asarray([mu_1_l])\n",
    "    print(\"---------\")\n",
    "    print(mu_1_l.shape, b_L.shape, z_1_L.shape)\n",
    "    print(np.asarray(x_u).shape, W_0_U.shape, W_1_U.shape)\n",
    "    \n",
    "    \n",
    "    out_l = min_of_linear_fun(np.concatenate((mu_1_l.flatten(), b_L.flatten(), z_1_L.flatten())), \n",
    "                                np.concatenate((np.asarray(x_u).flatten(), W_0_U.flatten(), W_1_U.flatten())),\n",
    "                                np.concatenate((np.asarray(x_l).flatten(), W_0_L.flatten(), W_1_L.flatten()))) + la_1_l\n",
    "\n",
    "\n",
    "    mu_1_u = np.asarray([mu_1_u])\n",
    "    out_u = max_of_linear_fun(np.concatenate((mu_1_u.flatten(), nu_02_u.flatten(), nu_12_u)), \n",
    "                                np.concatenate((np.asarray(x_u).flatten(), W_0_U.flatten(), W_1_U.flatten())),\n",
    "                                np.concatenate((np.asarray(x_l).flatten(),W_0_L.flatten(), W_1_L.flatten()))) + la_1_u\n",
    "\n",
    "    #print out_l[0], out_u[0]\n",
    "    #print 'range: ' + str(out_u[0] - out_l[0])\n",
    "    return [sW_0,sb_0,sW_1,sb_1],[out_l, out_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cce9be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# Full routine\n",
    "# ============\n",
    "def prob_veri(model, s0, s1, w_marg, samples, predicate, i0=0, depth=4):\n",
    "    assert(samples >= (depth)) #, \"Ensure samples > depth. Otherwise probability computation is unsound.\")\n",
    "    w_marg = w_marg*2\n",
    "    safe_weights = []\n",
    "    for i in trange(samples, desc=\"Checking Samples\"):\n",
    "        model.model.set_weights(model.sample())\n",
    "        ol, ou = propogate_lines(model, (s0+s1)/2, [s0, s1], w_margin=w_marg)\n",
    "        if(predicate(np.squeeze(s0), np.squeeze(s1), np.squeeze(ol), np.squeeze(ou))):\n",
    "            safe_weights.append(model.model.get_weights())\n",
    "    print(\"Found %s safe intervals\"%(len(safe_weights)))\n",
    "    p = compute_probability_bonferroni(model, safe_weights, w_marg, max_depth=depth)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7ccb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9192413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Samples:   0%|                                                                                         | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07213475 -0.01314103  0.07552157 -0.07011431  0.00535314 -0.0718822\n",
      " -0.01322735 -0.07246232  0.07064665 -0.07447143  0.06007013  0.02746662\n",
      "  0.01272532 -0.0222773  -0.03831224 -0.0486553 ]\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "(1568,) (1568,) (1568,)\n",
      "Zeta Shapes:  (1, 16) (1, 16)\n",
      "(16,)\n",
      "Bar shapes:  (16, 784) (16, 784) (16,)\n",
      "Bar shapes:  (16, 784) (16, 784) (16,)\n",
      "Bar shapes:  (16, 784) (16, 784) (16,)\n",
      "In Shapes:  (16, 10) (16, 784) (16, 784) (16,) (16, 784) (16, 784) (16,)\n",
      "W shape:  (16, 10)\n",
      "Nu shape:  (16, 784) (16, 784)\n",
      "W shape:  (16, 10)\n",
      "Nu shape:  (16, 784) (16, 784)\n",
      "ABC shapes:  (160, 784) (160, 784) (160,)\n",
      "ABC shapes:  (160, 784) (160, 784) (160,)\n",
      "---------\n",
      "(1, 784) (160, 784) (1, 16)\n",
      "(1, 784) (16, 784) (16, 10)\n",
      "(126240,) (13488,) (13488,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 13488 is out of bounds for axis 0 with size 13488",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mprob_veri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbayes_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_marg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicate_safe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mprob_veri\u001b[0;34m(model, s0, s1, w_marg, samples, predicate, i0, depth)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(samples, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking Samples\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mset_weights(model\u001b[38;5;241m.\u001b[39msample())\n\u001b[0;32m---> 10\u001b[0m     ol, ou \u001b[38;5;241m=\u001b[39m \u001b[43mpropogate_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ms0\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43ms1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(predicate(np\u001b[38;5;241m.\u001b[39msqueeze(s0), np\u001b[38;5;241m.\u001b[39msqueeze(s1), np\u001b[38;5;241m.\u001b[39msqueeze(ol), np\u001b[38;5;241m.\u001b[39msqueeze(ou))):\n\u001b[1;32m     12\u001b[0m         safe_weights\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_weights())\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mpropogate_lines\u001b[0;34m(model, x, in_reg, w_margin, act)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(mu_1_l\u001b[38;5;241m.\u001b[39mshape, b_L\u001b[38;5;241m.\u001b[39mshape, z_1_L\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(x_u)\u001b[38;5;241m.\u001b[39mshape, W_0_U\u001b[38;5;241m.\u001b[39mshape, W_1_U\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 209\u001b[0m out_l \u001b[38;5;241m=\u001b[39m \u001b[43mmin_of_linear_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu_1_l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_1_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_u\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_0_U\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_1_U\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_0_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_1_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m la_1_l\n\u001b[1;32m    214\u001b[0m mu_1_u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([mu_1_u])\n\u001b[1;32m    215\u001b[0m out_u \u001b[38;5;241m=\u001b[39m max_of_linear_fun(np\u001b[38;5;241m.\u001b[39mconcatenate((mu_1_u\u001b[38;5;241m.\u001b[39mflatten(), nu_02_u\u001b[38;5;241m.\u001b[39mflatten(), nu_12_u)), \n\u001b[1;32m    216\u001b[0m                             np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39masarray(x_u)\u001b[38;5;241m.\u001b[39mflatten(), W_0_U\u001b[38;5;241m.\u001b[39mflatten(), W_1_U\u001b[38;5;241m.\u001b[39mflatten())),\n\u001b[1;32m    217\u001b[0m                             np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39masarray(x_l)\u001b[38;5;241m.\u001b[39mflatten(),W_0_L\u001b[38;5;241m.\u001b[39mflatten(), W_1_L\u001b[38;5;241m.\u001b[39mflatten()))) \u001b[38;5;241m+\u001b[39m la_1_u\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mmin_of_linear_fun\u001b[0;34m(coef_vec, uppers, lowers)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(coef_vec)):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_vec[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m         val_min \u001b[38;5;241m=\u001b[39m val_min \u001b[38;5;241m+\u001b[39m coef_vec[i]\u001b[38;5;241m*\u001b[39m\u001b[43mlowers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     98\u001b[0m         val_min \u001b[38;5;241m=\u001b[39m val_min \u001b[38;5;241m+\u001b[39m coef_vec[i]\u001b[38;5;241m*\u001b[39muppers[i]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13488 is out of bounds for axis 0 with size 13488"
     ]
    }
   ],
   "source": [
    "xl = np.asarray([X_test[0] - 0.01])\n",
    "xu = np.asarray([X_test[0] + 0.01])\n",
    "\n",
    "def predicate_safe(iml, imu, ol, ou):\n",
    "    v1 = tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v2 = 1 - tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v1 = tf.squeeze(v1); v2 = tf.squeeze(v2)\n",
    "    worst_case = tf.math.add(tf.math.multiply(v2, ou), tf.math.multiply(v1, ol))\n",
    "    if(np.argmax(worst_case) == TRUE_VALUE):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "p = prob_veri(bayes_model, xl, xu, w_marg=3.5, samples=10, predicate=predicate_safe, i0=0, depth=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
