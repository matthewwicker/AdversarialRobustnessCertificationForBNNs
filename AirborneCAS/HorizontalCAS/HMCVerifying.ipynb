{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b53dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "    font-size: 24px;\n",
       "}\n",
       "\n",
       "div.output_area pre {\n",
       "    font-size: 24px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "    font-size: 24px;\n",
    "}\n",
    "\n",
    "div.output_area pre {\n",
    "    font-size: 24px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc50e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# !! THIS IS ONLY FOR RELU !! NO OTHER ACTIVATION SUPPORTED atm\n",
    "def get_alphas_betas(zeta_l, zeta_u, activation=\"relu\"):\n",
    "    alpha_L, alpha_U = list([]), list([])\n",
    "    beta_L, beta_U = list([]), list([])\n",
    "    for i in range(len(zeta_l)):\n",
    "        if(zeta_u[i] <= 0):\n",
    "            alpha_U.append(0); alpha_L.append(0); beta_L.append(0); beta_U.append(0)\n",
    "        elif(zeta_l[i] >= 0):\n",
    "            alpha_U.append(1); alpha_L.append(1); beta_L.append(0); beta_U.append(0)\n",
    "        else:\n",
    "            # For relu I have the points (zeta_l, 0) and (zeta_u, zeta_u)\n",
    "            a_U = zeta_u[i]/(zeta_u[i]-zeta_l[i]); b_U = -1*(a_U*zeta_l[i])\n",
    "    \n",
    "            #a_L = a_U ; b_L = 0\n",
    "            #if (zeta_u[i] + zeta_l[i]) >= 0:\n",
    "            #    a_L = 1 ;   b_L = 0\n",
    "            #else:\n",
    "            a_L = 0 ;   b_L = 0    \n",
    "            alpha_U.append(a_U); alpha_L.append(a_L); beta_L.append(b_L); beta_U.append(b_U)\n",
    "    return alpha_U, beta_U, alpha_L, beta_L\n",
    "\n",
    "\n",
    "\n",
    "def get_bar_lower(linear_bound_coef, mu_l, mu_u,\n",
    "                  nu_l, nu_u, lam_l, lam_u):\n",
    "    mu_l = np.squeeze(mu_l); mu_u = np.squeeze(mu_u); \n",
    "    mu_bar, nu_bar, lam_bar = [], [], []\n",
    "    \n",
    "    nu_bar = nu_l\n",
    "\n",
    "    #coef of the form - alpha_U, beta_U, alpha_L, beta_L\n",
    "    for i in range(len(linear_bound_coef)):\n",
    "        if(linear_bound_coef[i,2] >= 0):\n",
    "            mu_bar.append(linear_bound_coef[i,2] * mu_l[i])\n",
    "            for k in range(len(nu_bar)):\n",
    "                try:\n",
    "                    nu_bar[k][i] = linear_bound_coef[i,2] * np.asarray(nu_l[k][i])\n",
    "                except:\n",
    "                    print('error')\n",
    "            lam_bar.append(linear_bound_coef[i,2] * lam_l[i] + linear_bound_coef[i,3])\n",
    "        else:\n",
    "            mu_bar.append(linear_bound_coef[i,2] * mu_u[i])\n",
    "            for k in range(len(nu_bar)):\n",
    "                nu_bar[k][i] = linear_bound_coef[i,2] * nu_u[k][i]\n",
    "            lam_bar.append(linear_bound_coef[i,2] * lam_u[i] + linear_bound_coef[i,3])\n",
    "    return np.asarray(mu_bar), nu_bar, np.asarray(lam_bar)\n",
    "\n",
    "def get_bar_upper(linear_bound_coef, mu_l, mu_u,\n",
    "                  nu_l, nu_u, lam_l, lam_u):\n",
    "    mu_l = np.squeeze(mu_l); mu_u = np.squeeze(mu_u);  \n",
    "    mu_bar, nu_bar, lam_bar = [], [], []\n",
    "    nu_bar = nu_u\n",
    "    for i in range(len(linear_bound_coef)):\n",
    "        if(linear_bound_coef[i,0] >= 0):\n",
    "            mu_bar.append(linear_bound_coef[i,0] * mu_u[i])\n",
    "            for k in range(len(nu_bar)):\n",
    "                nu_bar[k][i] = linear_bound_coef[i,0] * np.asarray(nu_u[k][i])\n",
    "            lam_bar.append(linear_bound_coef[i,0] * lam_u[i] + linear_bound_coef[i,1])\n",
    "        else:\n",
    "            mu_bar.append(linear_bound_coef[i,0] * mu_l[i])\n",
    "            for k in range(len(nu_bar)):\n",
    "                nu_bar[k][i] = linear_bound_coef[i,0] * nu_l[k][i]\n",
    "            lam_bar.append(linear_bound_coef[i,0] * lam_l[i] + linear_bound_coef[i,1])\n",
    "    return np.asarray(mu_bar), nu_bar, np.asarray(lam_bar)\n",
    "\n",
    "def get_abc_lower(w, mu_l_bar, nu_l_bar, la_l_bar,\n",
    "               mu_u_bar, nu_u_bar, la_u_bar):\n",
    "    a, b, c = [], [], []\n",
    "    for i in range(len(w)):\n",
    "        curr_a = []\n",
    "        #curr_b = []\n",
    "        curr_c = []\n",
    "        for j in range(len(w[i])):\n",
    "            if(w[i][j] >= 0):\n",
    "                curr_a.append(w[i][j] * mu_l_bar[i])\n",
    "                curr_c.append(w[i][j] * la_l_bar[i])\n",
    "            else:\n",
    "                curr_a.append(w[i][j] * mu_u_bar[i])\n",
    "                curr_c.append(w[i][j] * la_u_bar[i])\n",
    "        a.append(curr_a)\n",
    "        \n",
    "        c.append(curr_c)\n",
    "    for k in range(len(nu_l_bar)): \n",
    "        curr_b = []\n",
    "        #for i in range(len(w)):\n",
    "        for j in range(len(w[i])):\n",
    "            curr_curr_b = []\n",
    "            #for j in range(len(w[i])):\n",
    "            for i in range(len(w)):\n",
    "                if(w[i][j] >= 0):\n",
    "                    curr_curr_b.append(w[i][j] * nu_l_bar[k][i])\n",
    "                else:\n",
    "                    curr_curr_b.append(w[i][j] * nu_u_bar[k][i])\n",
    "            curr_b.append(curr_curr_b)\n",
    "        b.append(curr_b)  \n",
    "        \n",
    "        \n",
    "    return np.asarray(a), b, np.asarray(c)\n",
    "\n",
    "\n",
    "def get_abc_upper(w, mu_l_bar, nu_l_bar, la_l_bar,\n",
    "               mu_u_bar, nu_u_bar, la_u_bar):\n",
    "    #This is anarchy\n",
    "    return get_abc_lower(w,mu_u_bar, nu_u_bar, la_u_bar,\n",
    "                         mu_l_bar, nu_l_bar, la_l_bar)\n",
    "\n",
    "\n",
    "def min_of_linear_fun(coef_vec, uppers, lowers):\n",
    "   #getting the minimum\n",
    "    val_min = 0\n",
    "    for i in range(len(coef_vec)):\n",
    "        if coef_vec[i] >=0:\n",
    "            val_min = val_min + coef_vec[i]*lowers[i]\n",
    "        else: \n",
    "            val_min = val_min + coef_vec[i]*uppers[i]\n",
    "    return val_min\n",
    "\n",
    "def max_of_linear_fun(coef_vec, uppers, lowers):\n",
    "    val_max = - min_of_linear_fun(-coef_vec, uppers, lowers)\n",
    "    return val_max\n",
    "\n",
    "\n",
    "def propogate_lines(x, x_l, x_u, weights, mean, var,\n",
    "                    w_margin=0.25, search_samps=100, act = 'relu'):\n",
    "\n",
    "    x = np.asarray(x); x = x.astype('float64')\n",
    "    \n",
    "    [mW_0, mb_0, mW_1, mb_1] = mean\n",
    "    [mW_0, mb_0, mW_1, mb_1] = var\n",
    "    try:\n",
    "        loaded_model = np.load(model_path, allow_pickle=True)\n",
    "        [mW_0, mb_0, mW_1, mb_1, dW_0, db_0, dW_1, db_1] = loaded_model['arr_0']\n",
    "        dWs = [dW_0,dW_1]\n",
    "        dbs = [db_0,db_1]\n",
    "        widths = [512]   \n",
    "    except:\n",
    "        with open(model_path, 'r') as pickle_file:\n",
    "            [mW_0, mb_0, mW_1, mb_1, dW_0, db_0, dW_1, db_1] = pickle.load(pickle_file)\n",
    "            dWs = [dW_0,dW_1]\n",
    "            dbs = [db_0,db_1]\n",
    "            widths = [512]   \n",
    "   \n",
    "      \n",
    "    n_hidden_layers = len(widths)\n",
    "    \n",
    "    #Code adaptation end. From now on it's the standard code \n",
    "     \n",
    "    #Step 1: Inputn layers -> Pre-activation function        \n",
    "    W_0_L, W_0_U, b_0_L, b_0_U = (sWs[0][0] - dWs[0]*w_margin,  sWs[0][0] + dWs[0]*w_margin, \n",
    "                                  sbs[0][0]-dbs[0]*w_margin, sbs[0][0]+dbs[0]*w_margin)\n",
    "    \n",
    "    W_0_L = W_0_L.T\n",
    "    W_0_U = W_0_U.T\n",
    "    \n",
    "    mu_0_L = W_0_L; mu_0_U = W_0_U\n",
    "    \n",
    "    n_hidden_1 = sWs[0][0].shape[1]\n",
    "    \n",
    "    nu_0_L = np.asarray([x_l for i in range(n_hidden_1) ])\n",
    "    nu_0_U = np.asarray([x_l for i in range(n_hidden_1) ])\n",
    "    la_0_L = - np.dot(x_l, W_0_L.T) + b_0_L\n",
    "    la_0_U = - np.dot(x_l, W_0_U.T) + b_0_U\n",
    "    \n",
    "    \n",
    "    # getting bounds on pre-activation fucntion\n",
    "    zeta_0_L = [ (min_of_linear_fun(np.concatenate((mu_0_L[i].flatten(), nu_0_L[i].flatten())), \n",
    "                                     np.concatenate((np.asarray(x_u).flatten(), W_0_U[i].flatten() )),\n",
    "                                     np.concatenate((np.asarray(x_l).flatten(), W_0_L[i].flatten() ))  )) for i in range(n_hidden_1)] \n",
    "   \n",
    "    zeta_0_L = np.asarray(zeta_0_L) + la_0_L\n",
    "     \n",
    "    zeta_0_U = [ (max_of_linear_fun(np.concatenate((mu_0_U[i].flatten(), nu_0_U[i].flatten())),\n",
    "                                     np.concatenate((np.asarray(x_u).flatten(), W_0_U[i].flatten())),\n",
    "                                     np.concatenate((np.asarray(x_l).flatten(), W_0_L[i].flatten()))  )) for i in range(n_hidden_1)]\n",
    "        \n",
    "    zeta_0_U = np.asarray(zeta_0_U) + la_0_U\n",
    "    \n",
    "    \n",
    "    #Initialising variable for main loop\n",
    "    curr_zeta_L = zeta_0_L\n",
    "    curr_zeta_U = zeta_0_U\n",
    "    curr_mu_L = mu_0_L\n",
    "    curr_mu_U = mu_0_U\n",
    "    curr_nu_L = [nu_0_L]\n",
    "    curr_nu_U = [nu_0_U]\n",
    "    curr_la_L = la_0_L\n",
    "    curr_la_U = la_0_U\n",
    "    \n",
    "    W_Ls = W_0_L.flatten()\n",
    "    W_Us = W_0_U.flatten()\n",
    "    #loop over the hidden layers\n",
    "    for l in range(1,n_hidden_layers+1):\n",
    "        if l < n_hidden_layers:\n",
    "            curr_n_hidden = widths[l]\n",
    "        else:\n",
    "            curr_n_hidden = 1\n",
    "            \n",
    "        LUB = np.asarray(get_alphas_betas(curr_zeta_L, curr_zeta_U))\n",
    "        LUB = np.asmatrix(LUB).transpose() \n",
    "        # Now evaluate eq (*) conditions:\n",
    "        curr_mu_L_bar, curr_nu_L_bar, curr_la_L_bar = get_bar_lower(LUB, curr_mu_L, curr_mu_U, \n",
    "                                                           curr_nu_L, curr_nu_U, \n",
    "                                                           curr_la_L, curr_la_U)\n",
    "\n",
    "        curr_mu_U_bar, curr_nu_U_bar, curr_la_U_bar = get_bar_upper(LUB, curr_mu_L, curr_mu_U, \n",
    "                                                           curr_nu_L, curr_nu_U, \n",
    "                                                           curr_la_L, curr_la_U)\n",
    "        \n",
    "        curr_z_L = [   min_of_linear_fun( [LUB[i,2]] , [curr_zeta_U[i]] , [curr_zeta_L[i]]     ) + LUB[i,3]\n",
    "                      for i in range(len(curr_zeta_U))    ]\n",
    "\n",
    "        #SUpper and lower bounds for weights and biases of current hidden layer\n",
    "        curr_W_L, curr_W_U, curr_b_L, curr_b_U = (sWs[l][0] - dWs[l]*w_margin,  sWs[l][0] + dWs[l]*w_margin,\n",
    "                                      sbs[l][0] - dbs[l]*w_margin, sbs[l][0] + dbs[l]*w_margin)\n",
    "    \n",
    "        a_L, b_L, c_L = get_abc_lower(curr_W_L, curr_mu_L_bar, curr_nu_L_bar, curr_la_L_bar,\n",
    "                               curr_mu_U_bar, curr_nu_U_bar, curr_la_U_bar)\n",
    "        \n",
    "        a_U, b_U, c_U = get_abc_upper(curr_W_U, curr_mu_L_bar, curr_nu_L_bar, curr_la_L_bar,\n",
    "                               curr_mu_U_bar, curr_nu_U_bar, curr_la_U_bar)\n",
    "        \n",
    "        curr_mu_L = np.sum(a_L, axis=0)\n",
    "        curr_mu_U = np.sum(a_U, axis=0)\n",
    "        curr_nu_L = []\n",
    "        curr_nu_U = []\n",
    "        for k in range(l-1):\n",
    "            curr_nu_L.append(np.sum(b_L[k], axis=1))\n",
    "            curr_nu_U.append(np.sum(b_U[k], axis=1))\n",
    "        \n",
    "        curr_nu_L.append(b_L[l-1])\n",
    "        curr_nu_U.append(b_U[l-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        curr_nu_L.append(np.asarray([curr_z_L for i in range(curr_n_hidden) ]))\n",
    "        curr_nu_U.append(np.asarray([curr_z_L for i in range(curr_n_hidden) ]))\n",
    "        \n",
    "            \n",
    "        curr_la_L = np.sum(c_L, axis=0) - np.dot(curr_z_L, curr_W_L) + curr_b_L\n",
    "        curr_la_U = np.sum(c_U, axis=0) - np.dot(curr_z_L, curr_W_U) + curr_b_U\n",
    "    \n",
    "\n",
    "            \n",
    "        curr_zeta_L = []\n",
    "        curr_zeta_U = []\n",
    "        \n",
    "        for i in range(curr_n_hidden):\n",
    "            ith_mu_L = curr_mu_L[i]\n",
    "            ith_mu_U = curr_mu_U[i]\n",
    "\n",
    "            \n",
    "            ith_W_Ls = np.concatenate( (W_Ls, curr_W_L.T[i]) )\n",
    "            ith_W_Us = np.concatenate( (W_Us, curr_W_U.T[i]) )\n",
    "            ith_nu_L = []\n",
    "            ith_nu_U = []\n",
    "            for k in range(len(curr_nu_L)):\n",
    "                ith_nu_L = np.concatenate(  ( ith_nu_L, np.asarray(curr_nu_L[k][i]).flatten()  )    )\n",
    "                ith_nu_U = np.concatenate(  ( ith_nu_U, np.asarray(curr_nu_U[k][i]).flatten()  )    )\n",
    "                \n",
    "               \n",
    "            curr_zeta_L.append( min_of_linear_fun( np.concatenate( (ith_mu_L, ith_nu_L) ) ,\n",
    "                                                       np.concatenate( (x_u, ith_W_Us     ) ) ,\n",
    "                                                       np.concatenate( (x_l, ith_W_Ls     ) )\n",
    "                                                      )   )  \n",
    "            \n",
    "            curr_zeta_U.append( max_of_linear_fun( np.concatenate( (ith_mu_U, ith_nu_U) ) ,\n",
    "                                                   np.concatenate( (x_u, ith_W_Us     ) ) ,\n",
    "                                                   np.concatenate( (x_l, ith_W_Ls     ) )\n",
    "                                                  )   ) \n",
    "        curr_zeta_L  = curr_zeta_L + curr_la_L\n",
    "        curr_zeta_U  = curr_zeta_U + curr_la_U\n",
    "        \n",
    "        W_Ls = np.concatenate((W_Ls ,   curr_W_L.T.flatten()  ))\n",
    "        W_Us = np.concatenate((W_Us ,   curr_W_U.T.flatten()  ))\n",
    "        \n",
    "    #Code adaptation for output:    \n",
    "    #end code adaptation for output\n",
    "    return [curr_zeta_L, curr_zeta_U]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
