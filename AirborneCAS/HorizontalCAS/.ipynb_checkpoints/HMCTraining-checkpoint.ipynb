{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b65518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "    font-size: 24px;\n",
       "}\n",
       "\n",
       "div.output_area pre {\n",
       "    font-size: 24px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "    font-size: 24px;\n",
    "}\n",
    "\n",
    "div.output_area pre {\n",
    "    font-size: 24px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30a0e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a693da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors/HCAS_BNN_0_20\n",
      "Loading Data for HCAS, pra 00, Network Version 6\n",
      "Setting up Model\n",
      "Ins and Outs:  3 5\n",
      "This optimizer does not have a default compilation method. Please make sure to call the correct .compile method before use.\n",
      "deepbayes: Using implicit prior\n",
      "(3, 125) 12.909944487358056\n",
      "(125, 5) 2.0\n",
      "deepbayes: Using implicit prior\n",
      "(3, 125) 12.909944487358056\n",
      "(125, 5) 2.0\n",
      "(1, 53792, 3) (1, 53792, 5, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (1, 53792, 5, 5) and (1, 53792, 5) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9de818708d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m     bayes_model.constraint_train(np.asarray([X_train]), np.asarray([y_train]), \n\u001b[1;32m    110\u001b[0m                             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.012\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                             np.asarray([X_train]), np.asarray([y_train]))\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mbayes_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Active/IEEEJournalCode/deepbayesHF/optimizers/phmc.py\u001b[0m in \u001b[0;36mconstraint_train\u001b[0;34m(self, X_train, y_train, X_l, X_u, X_test, y_test)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstraint_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_u\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_rets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_iterate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Active/IEEEJournalCode/deepbayesHF/optimizers/phmc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_test, y_test, X_l, X_u, constraint)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Evaluate the potential energy of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# Perform the burn-in of the chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Active/IEEEJournalCode/deepbayesHF/optimizers/phmc.py\u001b[0m in \u001b[0;36mevaluate_U\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         v_loss = losses.normal_potential_energy(labels, predictions, self.prior_mean,\n\u001b[0;32m--> 243\u001b[0;31m                                                self.prior_var, self.q, self.loss_func)\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mworst_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Active/IEEEJournalCode/deepbayesHF/optimizers/losses.py\u001b[0m in \u001b[0;36mnormal_potential_energy\u001b[0;34m(target, output, prior_mean, prior_var, q, loss_func)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormal_potential_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mpw_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mpw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m#print(\"DATA: \", pw_d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    143\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m   return backend.categorical_crossentropy(\n\u001b[0;32m-> 1666\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4837\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4838\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4839\u001b[0;31m   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4841\u001b[0m   \u001b[0;31m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \"\"\"\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1, 53792, 5, 5) and (1, 53792, 5) are incompatible"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../../')\n",
    "import deepbayesHF\n",
    "\n",
    "import tensorflow as tf\n",
    "from deepbayesHF import optimizers\n",
    "from deepbayesHF import PosteriorModel\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "######## OPTIONS #########\n",
    "ver = 6              # Neural network version\n",
    "table_ver = 6        # Table Version\n",
    "hu = 25              # Number of hidden units in each hidden layer in network\n",
    "saveEvery = 1000     # Epoch frequency of saving\n",
    "totalEpochs = 3000   # Total number of training epochs\n",
    "trainingDataFiles = \"./TrainingData/HCAS_rect_TrainingData_v%d_pra%d_tau%02d.h5\" # File format for training data\n",
    "nnetFiles  = \"./networks/HCAS_rect_v%d_pra%d_tau%02d_%dHU.nnet\" # File format for .nnet files\n",
    "modelFiles = \"./models/HCAS_rect_v%d_pra%d_tau%02d_%dHU.ckpt\" # File format for .nnet files\n",
    "tbFiles = \"./tensorboard/HCAS_rect_v%d_pra%d_tau%02d_%dHU\"\n",
    "##########################\n",
    "\n",
    "# Custom tensorflow session. Sets up training with either a cpu, gpu, or multiple gpus\n",
    "def get_session(gpu_ind,gpu_mem_frac=0.45):\n",
    "    \"\"\"Create a session that dynamically allocates memory.\"\"\"\n",
    "    if gpu_ind[0]>-1:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(np.char.mod('%d', gpu_ind))\n",
    "        config = tf.ConfigProto(device_count = {'GPU': len(gpu_ind)})\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = gpu_mem_frac\n",
    "        session = tf.Session(config=config)\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "        session = tf.Session()\n",
    "    return session\n",
    "\n",
    "# Function to compute network accuracy given. However, this does not \n",
    "# add the online costs that were used to generate the correct minimum cost index, so\n",
    "# these accuracies are only an estimate\n",
    "# Note from MRW: This doesnt make sense as a metric...\n",
    "def custAcc(y_true,y_pred):\n",
    "    maxesPred = tf.argmax(y_pred,axis=1)\n",
    "    inds = tf.argmax(y_true,axis=1)\n",
    "    diff = tf.cast(tf.abs(inds-maxesPred),dtype='float64')\n",
    "    ones = tf.ones_like(diff,dtype='float64')\n",
    "    zeros= tf.zeros_like(diff,dtype='float64')\n",
    "    l = tf.where(diff<0.5,ones,zeros)\n",
    "    return tf.reduce_mean(l)\n",
    "\n",
    "\n",
    "# The previous RA should be given as a command line input\n",
    "if len(sys.argv) > 2:\n",
    "    pra = 0 #int(sys.argv[1])\n",
    "    tau = 20 #int(sys.argv[2])\n",
    "    gpu = -1\n",
    "    print(\"Posteriors/HCAS_BNN_%s_%s\"%(pra, tau))\n",
    "    if len(sys.argv)>3:\n",
    "        gpu = int(sys.argv[3])\n",
    "\n",
    "    print(\"Loading Data for HCAS, pra %02d, Network Version %d\" % (pra, ver))\n",
    "    f       = h5py.File(trainingDataFiles % (table_ver,pra,tau),'r')\n",
    "    X_train = np.array(f['X']).astype('float32')\n",
    "    y_train       = np.array(f['y']).astype('float32')\n",
    "    Q       = np.array(f['y']).astype('float32')\n",
    "    means = np.array(f['means'])\n",
    "    ranges=np.array(f['ranges'])\n",
    "    mins = np.array(f['min_inputs'])\n",
    "    maxes = np.array(f['max_inputs'])\n",
    "\n",
    "    min_inputs      = \",\".join(np.char.mod('%f', mins))\n",
    "    max_inputs     = \",\".join(np.char.mod('%f', maxes))\n",
    "    means      = \",\".join(np.char.mod('%f', means))\n",
    "    ranges     = \",\".join(np.char.mod('%f', ranges))\n",
    "    \n",
    "    N,numInputs = X_train.shape\n",
    "    N,numOut = Q.shape\n",
    "    X_train = tf.cast(X_train, dtype=tf.float64)\n",
    "    y_train = tf.argmax(y_train,axis=1)\n",
    "\n",
    "    print(\"Setting up Model\")\n",
    "\n",
    "    #loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    y_train = tf.one_hot(y_train, depth=numOut)\n",
    "    y_train = tf.cast(y_train, dtype=tf.float64)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    # Use Keras to define our model\n",
    "    WIDTH = 125\n",
    "    model = Sequential()\n",
    "    model.add(Dense(WIDTH, activation=\"relu\", input_shape=(1, numInputs)))\n",
    "    model.add(Dense(numOut, activation=\"softmax\"))\n",
    "    print(\"Ins and Outs: \", numInputs, numOut)\n",
    "    # Use deepbayesHF to define our optimizer\n",
    "    optimizer = optimizers.PriorHamiltonianMonteCarlo()\n",
    "    bayes_model = optimizer.compile(model, loss_fn=loss, learning_rate = 0.1, mh_burn=False,\n",
    "                          epochs=25, decay=0.3, steps = 30, b_steps = 25, burn_in=20,\n",
    "                          rob_lam=0.8, classes = 5, path = \"Posteriors/HMC_HCAS_BNN_%s_%s\"%(pra, tau),\n",
    "                          inflate_prior=500., mode='classification') # select optimizer and set learning rate\n",
    "\n",
    "    # Train and save BNN using deepbayesHF\n",
    "    #bayes_model.train(np.asarray([X_train]), y_train, np.asarray([X_train]), np.asarray([y_train]))\n",
    "    bayes_model.constraint_train(np.asarray([X_train]), np.asarray([y_train]), \n",
    "                            np.asarray([X_train])-0.012, np.asarray([X_train])+0.012,\n",
    "                            np.asarray([X_train]), np.asarray([y_train]))\n",
    "    bayes_model.finalize_chain()\n",
    "    y_pred = bayes_model.predict(X_train)\n",
    "\n",
    "    #bayes_model.save(\"Posteriors/ROB_HCAS_BNN_%s_%s\"%(pra, tau))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb30f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model.save(\"Posteriors/HMC_HCAS_BNN_%s_%s\"%(pra, tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = PosteriorModel(\"Posteriors/HMC_HCAS_BNN_%s_%s\"%(pra, tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db32e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = bmodel.predict(X_train)\n",
    "\n",
    "y_pred_2 = bayes_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_max = np.max(y_pred_1, axis=1)\n",
    "y_pred_1 = np.argmax(y_pred_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.asarray(bmodel.sample()[0][0][0]))\n",
    "#print(np.asarray(bayes_model.posterior_samples[6][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7db1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0\n",
    "for i in range(len(y_pred_1)):\n",
    "    #print(y_pred[i], y_train[i])\n",
    "    if(y_pred_1[i] == y_train[i]):\n",
    "        print(y_pred_max[i])\n",
    "        corr += 1\n",
    "print(corr)\n",
    "print(corr/len(y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0\n",
    "y_pred_max = \n",
    "for i in range(len(y_pred_2)):\n",
    "    #print(y_pred[i], y_train[i])\n",
    "    if(y_pred_2[i] == y_train[i]):\n",
    "        corr += 1\n",
    "print(corr)\n",
    "print(corr/len(y_pred_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
